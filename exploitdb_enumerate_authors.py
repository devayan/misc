import urllib2
import BeautifulSoup
from collections import defaultdict


ua="Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2.18) Gecko/20110614 Firefox/3.6.18"

def get_exploitdb_author(id):
	opener = urllib2.build_opener()
	opener.addheaders = [('User-agent', ua)]
	expl=defaultdict(list)
	url='http://www.exploit-db.com/author/?a='+str(id)
	next=1
	
	while (next):
	
		data=opener.open(url).read()
		if BeautifulSoup.BeautifulSoup(data).find('div',{'class':'pagination'}) != None:
			if BeautifulSoup.BeautifulSoup(data).find('div',{'class':'pagination'}).findAll('a',{'class':'color'})[-1].contents[0] == 'next':
				next=1
				url=BeautifulSoup.BeautifulSoup(data).find('div',{'class':'pagination'}).findAll('a',{'class':'color'})[-1]['href']
			else:
				next=0
		else:
			next=0
			
		html=BeautifulSoup.BeautifulSoup(data)
		title=html.find('td',{'class':'list_explot_author'}).a['title']
		main=html.find('table',{'class':'exploit_list'}).tbody.findAll('tr')
		
		for i in main:
			date=str(i.find('td',{'class':'list_explot_date'}).contents[0])
			clicks=str(i.find('td',{'class':'list_explot_clicks'}).contents[0]).replace('\n','').replace('\t','')
			if i.find('td',{'class':'list_explot_platform'}).find('a') != None:
				platform=str(i.find('td',{'class':'list_explot_platform'}).a.contents[0])  
			else:
				platform='unknown'
			desc=str(i.find('td',{'class':'list_explot_description'}).a.contents[0])
			explurl=str(i.find('td',{'class':'list_explot_description'}).a['href'])
			expl[platform].append([date,clicks,desc,explurl])
	
	opener.close()
	return title,dict(expl)


def get_exploitdb_category(category):
	opener = urllib2.build_opener()
	opener.addheaders = [('User-agent', ua)]
	expl=defaultdict(list)
	url='http://www.exploit-db.com/'+category
	next=1

	while (next):
		data=opener.open(url).read()
		if BeautifulSoup.BeautifulSoup(data).find('div',{'class':'pagination'}) != None:
			if BeautifulSoup.BeautifulSoup(data).find('div',{'class':'pagination'}).findAll('a',{'class':'color'})[-1].contents[0] == 'next':
				next=1
				url=BeautifulSoup.BeautifulSoup(data).find('div',{'class':'pagination'}).findAll('a',{'class':'color'})[-1]['href']
			else:
				next=0
		else:
			next=0
			
		html=BeautifulSoup.BeautifulSoup(data)
		main=html.find('table',{'class':'exploit_list'}).tbody.findAll('tr')
		
		for i in main:
			title=html.find('td',{'class':'list_explot_author'}).a['title']
			date=str(i.find('td',{'class':'list_explot_date'}).contents[0]).replace('\n','').replace('\t','')
			clicks=str(i.find('td',{'class':'list_explot_clicks'}).contents[0]).replace('\n','').replace('\t','')
			if i.find('td',{'class':'list_explot_platform'}).find('a') != None:
				platform=str(i.find('td',{'class':'list_explot_platform'}).a.contents[0])  
			else:
				platform='unknown'
			desc=str(i.find('td',{'class':'list_explot_description'}).a.contents[0])
			explurl=str(i.find('td',{'class':'list_explot_description'}).a['href'])
			expl[title].append([platform,date,clicks,desc,explurl])

	opener.close()
	return dict(expl)


#(t,e)=get_exploitdb_author(3211)		
e=get_exploitdb_category("shellcode")
for i in e.keys():
	print i,len(e[i]),e[i]
